{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# 各個元件 conv2d,dropout,....\n",
    "import torch.nn as nn\n",
    "# 各種function: mapooling,ReLu,Loss,.....\n",
    "import torch.nn.functional as F\n",
    "# 各種最佳化(gradient descent)方式: adam, SGD,....\n",
    "import torch.optim as optm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "建立neural network:\n",
    "1. extend nn.Module\n",
    "2. override __init__\n",
    "   initialize your neural network components at here. ex: conv2d, dropout,......\n",
    "3. override forward\n",
    "   to define you network architecture at here\n",
    "'''\n",
    "class minst_nn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(minst_nn, self).__init__()\n",
    "        \n",
    "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "  \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        \n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "data_train = datasets.MNIST(root = \"./data/\",\n",
    "                            transform=transforms,\n",
    "                            train = True,\n",
    "                            download = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料讀取\n",
    "#### torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False,  sampler=None, batch_sampler=None, num_workers=0,     collate_fn=None, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None, multiprocessing_context=None)\n",
    "shuffle: 隨機排序              \n",
    "### Pytorch基本圖像操作\n",
    "#### torchvision.transforms\n",
    "在使用torchvision.transforms時，我們通常使用transforms.Compose將transforms组合在一起。 <br>\n",
    "transform = transforms.Compose([transforms list])\n",
    "1. PIL.image,numpy.ndarray 和 pytorch tensor 轉換 <br>\n",
    "   a. transforms.ToTensor() 轉成(c,h,w)範圍[0,1]<br>\n",
    "   b. transforms.ToPILImage() 轉成(c,h,w)範圍[0,1]<br>\n",
    "   c. transfroms.numpy() <br>\n",
    "2. normalization <br>\n",
    "   a. transforms.Normalize((mean),(std)) : 將範圍轉成[-1,1]\n",
    "3. 其他圖像前處理(crap...等)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n計算mean以及std，供transforms.Normalize使用\\n這邊dataset以datasets.MNIST為例\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "計算mean以及std，供transforms.Normalize使用\n",
    "這邊dataset以datasets.MNIST為例\n",
    "'''\n",
    "# import numpy as np\n",
    "# def get_mean_std(dataset):\n",
    "#     train_loader = torch.utils.data.DataLoader(\n",
    "#             datasets.MNIST('./data', train=True, download=True,\n",
    "#                            transform=transforms.Compose([\n",
    "#                                transforms.ToTensor()\n",
    "#                            ])),batch_size=60000, shuffle=True)\n",
    "#     train = iter(train_loader).next()[0]\n",
    "#     mean = np.mean(train.numpy(), axis=(0,1,2,3))\n",
    "#     std = np.std(train.numpy(), axis=(0,1,2,3))\n",
    "#     return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_batch_size, test_batch_size):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST('./data', train=True, download=True,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.1307,), (0.3081,))\n",
    "                           ])),\n",
    "            batch_size=train_batch_size, shuffle=True)#, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST('./data', train=False, download=True,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.1307,), (0.3081,))\n",
    "                           ])),\n",
    "            batch_size=train_batch_size, shuffle=True)#, **kwargs)\n",
    "    return (train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "#### Design the train & evaluate fucntion\n",
    "\n",
    "##### Train\n",
    "\n",
    "* ###### tqdm(進度條)\n",
    "  tqdm(train_set, leave=True, total=len(train_set))\n",
    "\n",
    "* ###### train\n",
    "  1. 將model設定成train模式\n",
    "  2. 將data, target放入device\n",
    "  3. [(重要)更新參數前一定要將之前的grad設定成0](https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "     \n",
    "  4. 將data丟入model\n",
    "  5. 計算loss\n",
    "  6. backpropogation\n",
    "  7. 更新參數optimizer.step()\n",
    "\n",
    "* ###### evaluation\n",
    "  1. 將model設定成evaluation模式 <br>\n",
    "     eval()时，框架會自動把BN和DropOut固定住，不會取平均，而是用訓練好的值，不然的话，一旦test的batch_size过小，很容易就會被BN層導致  生成圖片顏色失真！\n",
    "  2. evaluation不需要計算gradien因此需要設定成torch.no_gradt模式\n",
    "  3. 將data, target放入device\n",
    "  4. 將data丟入model\n",
    "  5. 計算loss\n",
    "  6. 將out轉成target的格式 <br>\n",
    "     output.argmax(dim=1, keepdim=True)\n",
    "  7. 計算準確率 <br>\n",
    "     correct += pred.eq(target.view_as(pred)).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(arg, train_set, model, optimizer, epoch):\n",
    "def train(train_set, model, optimizer, epoch, num_epochs, device):\n",
    "    model.train()\n",
    "    idx = 0\n",
    "    with tqdm(train_set, leave=True, total=len(train_set)) as t:\n",
    "        t.set_description('Epoch %d/%d' %(epoch, num_epoch))\n",
    "        for data, target in t:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            idx += 1\n",
    "            if idx % len(train_set) != 0:\n",
    "                t.set_description(train_loss=loss.item())\n",
    "            else:\n",
    "                val_loss, accuracy = evaluate(globals.test_set, model)\n",
    "                t.set_description(train_loss=loss.item(), val_loss=val_loss, acc=accuracy)\n",
    "            \n",
    "\n",
    "def evaluate(test_set, model, device):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_set:\n",
    "        with torch.no_grad():\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss += F.nll_loss(output, target)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    accuracy = 100. * correct / len(test_set.dataset)\n",
    "    return loss, accuracy\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "\n",
    "#### training\n",
    "1. 將model丟入device(GPU or CPU)\n",
    "2. 設定optimizer & 調整learning rate的方式(optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same\n",
    "#GPU版本的torch要加上.to(device)，不然會出現cpu版本跟gpu版本tensor 導致error\n",
    "model = minst_nn().to(device)\n",
    "optimizer = optm.Adam(model.parameters())\n",
    "schedule = StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded\n",
      "Files already downloaded\n"
     ]
    }
   ],
   "source": [
    "(train_set, test_set) = load_data(64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train(train_set, model, optimizer, epoch, num_epochs, device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-66840131e563>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     print('Epoch: {}/{}\\t Loss:{:.6f}'.format(\n",
      "\u001b[0;32m~/Documents/Kaggle/KKbox/venv/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Kaggle/KKbox/venv/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "jupyter notebook實驗用寫法\n",
    "'''\n",
    "# num_epochs = 10\n",
    "# for epoch in range(1, num_epochs+1):\n",
    "#     model.train()\n",
    "#     with tqdm(train, leave=True, total=len(train)) as t:\n",
    "#         t.set_description('Epoch %4d/%4d' %(epoch, num_epochs))\n",
    "#         idx = 0\n",
    "#         for data, target in t:\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             output = model(data)\n",
    "#             loss = F.nll_loss(output, target)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             idx += 1\n",
    "#             if idx % len(train) != 0:\n",
    "#                 t.set_postfix(train_loss=loss.item())\n",
    "#             else:\n",
    "#                 model.eval()\n",
    "#                 val_loss = 0\n",
    "#                 correct = 0\n",
    "#                 with torch.no_grad():\n",
    "#                     for data, target in test:\n",
    "#                         data, target = data.to(device), target.to(device)\n",
    "#                         output = model(data)\n",
    "#                         val_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "#                         pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "#                         correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "#                 val_loss /= len(test.dataset)\n",
    "#                 t.set_postfix(train_loss=loss.item(), val_loss=val_loss, acc= 100. * correct/len(test.dataset))\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model架構可視化\n",
    "* ##### 直接print\n",
    "* ##### 使用torchsummary套件(keras格式)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minst_nn(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 26, 26]             320\n",
      "       BatchNorm2d-2           [-1, 32, 26, 26]              64\n",
      "            Conv2d-3           [-1, 64, 24, 24]          18,496\n",
      "       BatchNorm2d-4           [-1, 64, 24, 24]             128\n",
      "         Dropout2d-5           [-1, 64, 12, 12]               0\n",
      "            Linear-6                  [-1, 128]       1,179,776\n",
      "         Dropout2d-7                  [-1, 128]               0\n",
      "            Linear-8                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 1,200,074\n",
      "Trainable params: 1,200,074\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.96\n",
      "Params size (MB): 4.58\n",
      "Estimated Total Size (MB): 5.55\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model,(1,28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load custom dataset \n",
    "1. 要創建一個class繼承 torch.utils.data.Dataset <br>\n",
    "2. override __init__, __len__, __getitem__ <br>\n",
    "3. 傳入Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from glob import glob\n",
    "import os, io\n",
    "import pandas as pd\n",
    "class tree_leaf_dataset(Dataset):\n",
    "    def __init__(self, root_dir, train=True):\n",
    "        self.root_dir = root_dir\n",
    "        self.train = train\n",
    "        if train: \n",
    "            dir_type = 'train'\n",
    "        else:\n",
    "            dir_type = 'test'\n",
    "        paths = []\n",
    "        labels = []\n",
    "        label = 0\n",
    "        folders = glob('r',root_dir + '/' + dir_type + '/image/*')\n",
    "        for f in folders:\n",
    "            if os.path.isdir(f):\n",
    "                paths += glob(f + '/*.[Jj][Pp][Gg]')\n",
    "                labels += [label] * len(paths)\n",
    "        image_df = pd.DataFrame({\n",
    "            'path': paths,\n",
    "            'label': labels\n",
    "        })\n",
    "        self.image_df = image_df\n",
    "    def __len__(self):\n",
    "        return len(self.image_df)\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor():\n",
    "            idx = idx.tolist()\n",
    "        image_path = self.image_df.iloc[idx, 0]\n",
    "        image = io.imread(image_path)\n",
    "        label = self.image_df.iloc[idx, 1]\n",
    "        sample = {'image': image, 'label': label}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### command line \n",
    "#### argparse.ArgumentParser\n",
    "add_argument常用參數 <br>\n",
    "   1. '-xxx' & 'xxx' : 有-帶表示optional argument，沒有則是positional argument <br>\n",
    "   2. type : 型別 <br>\n",
    "   3. default <br>\n",
    "   4. dest : 指定寫code的時候call該參數的參數名 <br>\n",
    "   5. metavar: 代表help中顯示的參數名,通常記入完整的參數名\n",
    "   6. help: help中的幫助訊息\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "\n",
    "# parse = argparse.ArgumentParser()\n",
    "# 試寫\n",
    "# parse.add_argument('-batch_size', type=int, default='64', dest='train_batch', metavar='train batch size',\\\n",
    "#                    help='input batch size for training (default: 64)')\n",
    "# parse.add_argument('-test_batch_size', type=int, default='64', dest='test_batch',metavar='test_batch_size',\\\n",
    "#                   help='input batch size for training (default: 64)'))\n",
    "\n",
    "#實務上做法是將參數寫在config,命令列只傳config檔路徑\n",
    "# parse.add_argument('-c', type=str, dest= 'config_path', metavar='config file path')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
